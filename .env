# Smart City Assistant Configuration
# Copy this file to .env in your project root

# Ollama Configuration
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=llama2

# API Configuration  
API_PORT=8000
STREAMLIT_PORT=8501

# Logging
LOG_LEVEL=INFO

# Data Configuration
KNOWLEDGE_BASE_PATH=F:\\Ellucian\\claude\\knowledge.json

# Optional: Vector Database Configuration
VECTOR_DB_TYPE=faiss  # Options: faiss, chromadb, pinecone
PINECONE_API_KEY=your_pinecone_key_here
PINECONE_ENVIRONMENT=your_pinecone_env_here

# Optional: Performance Tuning
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
RETRIEVAL_K=5